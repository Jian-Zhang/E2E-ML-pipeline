{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using pytorch_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this demo using the Shell below(Run on Standalone mode, before run the below, you should check if spark set to Standalone mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/04/15 17:18:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "20/04/15 17:18:31 WARN spark.SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "! export SPARK_LOCAL_IP=127.0.0.1\n",
    "\n",
    "! sh /home/sparkuser/jupyter/Bin/H2O/h2o_sparklin_simple.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pysparkling import *\n",
    "from datetime import datetime\n",
    "import h2o\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start SparkSession and H2OContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Proxy is defined in the environment: http_proxy. This may interfere with your H2O Connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://10.16.4.4:54325 ....... failed.\n"
     ]
    },
    {
     "ename": "H2OConnectionError",
     "evalue": "Could not establish link to the H2O cloud http://10.16.4.4:54325 after 5 retries\n[37:28.90] H2OConnectionError: Timeout after 3.086s\n[37:32.11] H2OConnectionError: Timeout after 3.010s\n[37:35.32] H2OConnectionError: Timeout after 3.011s\n[37:38.53] H2OConnectionError: Timeout after 3.010s\n[37:41.74] H2OConnectionError: Timeout after 3.011s",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-921601fdc190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SparklingWaterApp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mH2OContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ai/h2o/sparkling/H2OContext.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(spark, conf, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Create H2O REST API client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mh2o_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__isClientConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mh2o_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__h2o_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mh2o_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setClientConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ai/h2o/sparkling/H2OContext.py\u001b[0m in \u001b[0;36m__h2o_connect\u001b[0;34m(h2o_context, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh2o_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_ip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh2o_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(server, url, ip, port, https, verify_ssl_certificates, cacert, auth, proxy, cookies, verbose, config)\u001b[0m\n\u001b[1;32m    101\u001b[0m                                      \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_ssl_certificates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_ssl_certificates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcacert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcacert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                                      \u001b[0mproxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                                      verbose=verbose)\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(server, url, ip, port, name, https, auth, verify_ssl_certificates, cacert, proxy, cookies, verbose, _msgs)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0;31m# If a server is unable to respond within 1s, it should be considered a bug. However we disable this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# setting for now, for no good reason other than to ignore all those bugs :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_test_connection\u001b[0;34m(self, max_retries, messages)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             raise H2OConnectionError(\"Could not establish link to the H2O cloud %s after %d retries\\n%s\"\n\u001b[0;32m--> 684\u001b[0;31m                                      % (self._base_url, max_retries, \"\\n\".join(errors)))\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OConnectionError\u001b[0m: Could not establish link to the H2O cloud http://10.16.4.4:54325 after 5 retries\n[37:28.90] H2OConnectionError: Timeout after 3.086s\n[37:32.11] H2OConnectionError: Timeout after 3.010s\n[37:35.32] H2OConnectionError: Timeout after 3.011s\n[37:38.53] H2OConnectionError: Timeout after 3.010s\n[37:41.74] H2OConnectionError: Timeout after 3.011s"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName(\"SparklingWaterApp\").getOrCreate()\n",
    "hc=H2OContext.getOrCreate(spark=spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1=datetime.now()\n",
    "print(\"====================Data Prepare=======================\")\n",
    "data=h2o.import_file(path=\"/home/sparkuser/jupyter/Bin/NYC_Taxi_Fare/input/trainCleanData.csv\")\n",
    "time1_1=datetime.now()\n",
    "print(\"data load time:\")\n",
    "print(time1_1-time1)\n",
    "\n",
    "df_train=hc.asSparkFrame(data)\n",
    "\n",
    "df_train.createOrReplaceTempView(\"nyc\")\n",
    "\n",
    "nyc_data=spark.sql(\"\"\"SELECT pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, passenger_count, fare_amount from nyc\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "train=hc.asH2OFrame(nyc_data, \"nyc_dataTable\")\n",
    "\n",
    "predictor_columns=train.col_names[0:4]\n",
    "lable_column=\"fare_amount\"\n",
    "time2=datetime.now()\n",
    "data_prepare_time=time2-time1\n",
    "print(\"Data Prepare Consuming Time:\")\n",
    "print(data_prepare_time)\n",
    "print(\"===================End Data Prepare==================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.random_forest import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"======================Model Train============================\")\n",
    "rf_model=H2ORandomForestEstimator(ntrees=20, max_depth=5, nfolds=10)\n",
    "rf_model.train(x=predictor_columns,y=lable_column,training_frame=train)\n",
    "print(rf_model)\n",
    "time3=datetime.now()\n",
    "model_train_time=time3-time2\n",
    "print(\"Model Train Consuming Time:\")\n",
    "print(model_train_time)\n",
    "\n",
    "print(\"====================End Model Train==========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===================Evaluation result=========================\")\n",
    "\n",
    "\n",
    "test_data=h2o.import_file(path=\"/home/sparkuser/jupyter/Bin/NYC_Taxi_Fare/input/testCleanData.csv\")\n",
    "\n",
    "\n",
    "df_test=hc.asSparkFrame(test_data)\n",
    "\n",
    "df_test.createOrReplaceTempView(\"nyc_test\")\n",
    "\n",
    "nyc_test_data=spark.sql(\"\"\"SELECT pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, passenger_count, fare_amount from nyc_test\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "test=hc.asH2OFrame(nyc_test_data, \"nyc_test_dataTable\")\n",
    "\n",
    "\n",
    "test_result=rf_model.predict(test)\n",
    "\n",
    "def RMSE(x, y):\n",
    "    return np.sqrt(((x - y) ** 2).mean())\n",
    "\n",
    "\n",
    "rmse_value=RMSE(test_result,test[\"fare_amount\"])\n",
    "print(test_result)\n",
    "print(\"RMSE value\")\n",
    "print(rmse_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Prepare Consuming Time:\")\n",
    "print(data_prepare_time)\n",
    "print(\"Model Train Consuming Time:\")\n",
    "print(model_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two nodes, ntrees=20, max_depth=20, nfolds=10,10 cores\n",
    "RMSE value\n",
    "[19.29719719]\n",
    "Data Prepare Consuming Time:\n",
    "0:00:27.503874\n",
    "Model Train Consuming Time:\n",
    "0:34:31.678458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two nodes: ntrees=20, max_depth=20, nfolds=10,10 cores\n",
    "RMSE value\n",
    "[19.60689014]\n",
    "Data Prepare Consuming Time:\n",
    "0:01:07.487494\n",
    "Model Train Consuming Time:\n",
    "0:35:37.384876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single node: ntrees=20, max_depth=20, nfolds=10,10 cores\n",
    "RMSE value\n",
    "[19.30460253]\n",
    "Data Prepare Consuming Time:\n",
    "0:01:06.381584\n",
    "Model Train Consuming Time:\n",
    "0:35:44.261877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single node: ntrees=20, max_depth=5, nfolds=10,10 cores\n",
    "data load time:\n",
    "0:00:51.688446\n",
    "RMSE value\n",
    "[19.72957374]\n",
    "Data Prepare Consuming Time:\n",
    "0:01:08.218417\n",
    "Model Train Consuming Time:\n",
    "0:08:03.625978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single node: ntrees=20, max_depth=5, nfolds=10,10 cores\n",
    "data load time:\n",
    "0:00:53.886734\n",
    "RMSE value\n",
    "[19.7442661]\n",
    "Data Prepare Consuming Time:\n",
    "0:01:07.930413\n",
    "Model Train Consuming Time:\n",
    "0:07:38.896936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single node: ntrees=20, max_depth=5, nfolds=10,20 cores\n",
    "data load time:\n",
    "0:01:00.702585\n",
    "RMSE value\n",
    "[19.70716208]\n",
    "Data Prepare Consuming Time:\n",
    "0:01:17.942207\n",
    "Model Train Consuming Time:\n",
    "0:04:34.257820"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single node: ntrees=20, max_depth=5, nfolds=10,20 cores\n",
    "RMSE value\n",
    "[19.74521829]\n",
    "Data Prepare Consuming Time:\n",
    "0:01:15.422524\n",
    "Model Train Consuming Time:\n",
    "0:04:36.551092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single node: ntrees=20, max_depth=20, nfolds=10,20 cores\n",
    "data load time:\n",
    "0:01:00.741514\n",
    "RMSE value\n",
    "[19.38341794]\n",
    "Data Prepare Consuming Time:\n",
    "0:01:18.341583\n",
    "Model Train Consuming Time:\n",
    "0:23:21.249120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single node: ntrees=20, max_depth=20, nfolds=10,40 cores\n",
    "RMSE value\n",
    "[19.41381396]\n",
    "Data Prepare Consuming Time:\n",
    "0:01:42.192490\n",
    "Model Train Consuming Time:\n",
    "0:18:25.526213"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
